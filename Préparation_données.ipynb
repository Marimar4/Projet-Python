{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. CHOMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imstallation et importation des packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" %pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install openpyxl\n",
    "%pip install pycodestyle\n",
    "%pip install pycountry\n",
    "%pip install seaborn\n",
    "%pip install pickleshare\"\"\"\n",
    "import pycodestyle as pep8\n",
    "import openpyxl as xl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pycountry\n",
    "import seaborn as sns\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation de la BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate=pd.read_excel(\"C:/Users/yousr/Downloads/Projet_py/Unemployment Rate.xlsx\", sheet_name='monthly' , index_col=0 )\n",
    "rate.head(5)\n",
    "rate.index = pd.to_datetime(rate.index,format='%YM%m')\n",
    "rate.index =rate.index.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noms des colonnes\n",
    "col_names=rate.columns\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type de données de chaque colonne \n",
    "datas_type= rate.dtypes\n",
    "print(datas_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = rate[rate.duplicated()]\n",
    "duplicates.head(5) # 0 doublons dans notre DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erreurs de frappes pour la colonne index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate.index = pd.to_datetime(rate.index, errors='coerce')\n",
    "errors = rate[rate.index.isnull()]\n",
    "errors.head(10) # Pas d'erreurs #########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction de DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garder uniquement les pays dans la DF : Méthode search_fuzzy de pycountry ###############################################################\n",
    "\n",
    "def detect_countries(col_names):\n",
    "    countries_detected = []\n",
    "    \n",
    "    for name in col_names:\n",
    "        try:\n",
    "            # Essayer de trouver le pays par son nom\n",
    "            pays= pycountry.countries.search_fuzzy(name)[0]\n",
    "            countries_detected.append(pays.name)\n",
    "        except LookupError:\n",
    "            # Ignorer les noms qui ne correspondent à aucun pays\n",
    "            pass\n",
    "    \n",
    "    return countries_detected\n",
    "\n",
    "# Liste des pays detectés\n",
    "\n",
    "countries_detected = detect_countries(col_names)\n",
    "print(\"Noms de pays détectés :\", countries_detected)\n",
    "\n",
    "# Longeur des listes : countries_detected et col_names\n",
    "print(len(countries_detected))\n",
    "print(len(col_names))\n",
    "\n",
    "# Différence entre les deux listes pour obtenir les noms des colonnes ignorées par la fonction detect_countries\n",
    "#L'objectif est de vérifier si des pays ont été omis par la fonction detect_countries\n",
    "\n",
    "# Pays dans col_names et pas dans countries_detected\n",
    "diff= list(set(col_names) - set(countries_detected))\n",
    "print(diff) \n",
    "\n",
    "# Pays dans countries_detected et pas dans col_names\n",
    "diff2= list(set(countries_detected)- set(col_names))\n",
    "print(diff2)\n",
    "\n",
    "countries_omitted =['Korea, Rep.', 'Taiwan, China', 'Hong Kong SAR, China', 'Czech Republic', 'Egypt, Arab Rep.', 'Venezuela, RB'] ####################\"\"\n",
    "concat = countries_detected + countries_omitted \n",
    "\n",
    "# Enfin, la liste finale des pays à retenir dans la DF\n",
    "countries_detected =list(set(concat)- set(diff2))\n",
    "print(countries_detected)\n",
    "\n",
    "# La DF taux de chomage à retenir\n",
    "rate_filter= rate[countries_detected]\n",
    "rate_filter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour faciliter la lecture de la DF, on remplace les noms des pays par leurs codes ISO  correspondant\n",
    "\n",
    "# Dictionnaire de correspondance entre noms complets des pays et leurs codes\n",
    "corresp = {country.name: country.alpha_3 for country in pycountry.countries}\n",
    "\n",
    "# Liste initiale des noms complets des colonnes\n",
    "country = countries_detected\n",
    "# Transformation des noms complets des colonnes en abréviations\n",
    "country_codes = [corresp.get(pays, pays) for pays in country]\n",
    "\n",
    "# Remplacement des noms des pays par leurs codes dans la merged\n",
    "rate_filter.columns=country_codes\n",
    "rate_filter.columns\n",
    "rate_filter.head(5)\n",
    "\n",
    "#Ordre alphabétique des colonnes \n",
    "rate_filter_sort= rate_filter.sort_index(axis=1)\n",
    "rate_filter_sort.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation des NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des valeurs manquantes NA\n",
    "import missingno as msno\n",
    "# Diagramme à barres des valeurs manquantes\n",
    "msno.bar(rate_filter_sort)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# % des NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le taux de valeurs manquantes dans chaque colonne\n",
    "size = rate_filter_sort.shape\n",
    "nan_sum = rate_filter_sort.isna().sum() # Total du nombre de NA par colonne\n",
    "nan_percent = nan_sum.sort_values(ascending=True) * 100 / size[0]\n",
    "print(nan_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seuil des NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les colonnes avec un pourcentage de valeurs manquantes supérieur à 40%\n",
    "cols_to_drop = nan_percent[nan_percent > 40].index\n",
    "print(cols_to_drop)\n",
    "\n",
    "# Supprimer les colonnes de la DataFrame\n",
    "rate_filter_sort.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type de données de chaque colonne \n",
    "data_type = rate_filter_sort.dtypes\n",
    "print(data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation des NA\n",
    "\n",
    "#rate_filter_sort_inter=rate_filter_sort.interpolate(method='linear', axis=0, limit=None, inplace=False, limit_direction=None, limit_area=None)\n",
    "\n",
    "#rate_filter_sort.fillna(value=None, method='ffill', axis=None, inplace=False, limit=None)\n",
    "\n",
    "rate_no_na = rate_filter_sort.fillna(rate_filter_sort.mean())\n",
    "\n",
    "#rate_filter_sort_fill= rate_filter_sort.iloc[-5:].ffill()\n",
    "\n",
    "indice_premiere_na = rate_filter_sort.isna().any(axis=1).idxmax()\n",
    "print(indice_premiere_na)\n",
    "\n",
    "#numero_ligne = rate_filter_sort.index.get_loc(indice_premiere_na) + 1\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "date_today = datetime.now()\n",
    "\n",
    "# Extrait l'année de la date actuelle\n",
    "current_year = date_today.year\n",
    "str(current_year)\n",
    "rate_filter_sort.index = pd.to_datetime(rate_filter_sort.index, format='mixed')\n",
    "\n",
    "\n",
    "rate_filter_sort.index = rate_filter_sort.index.astype(str)\n",
    "rate_current_year = rate_filter_sort[rate_filter_sort.index.str.contains(current_year)]\n",
    "\n",
    "\n",
    "#rate_filter_sort.index = pd.to_datetime(rate_filter_sort.index)\n",
    "\n",
    "#year2023 =rate_filter_sort.loc[rate_filter_sort.index.year == 2023]\n",
    "\n",
    "#.fillna(rate_filter_sort.mean())\n",
    "print(rate_filter_sort.index.dtype) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valeurs abérrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les valeurs abérrantes \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=rate_no_na)\n",
    "plt.title('Boîtes à moustaches des séries temporelles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_no_na.index = pd.to_datetime(rate_no_na.index, format='%Y-%m-%d')\n",
    "\n",
    "# Grouper par année et vérifier si tous les mois sont présents\n",
    "rate_12= rate_no_na.groupby(rate_no_na.index.year).filter(lambda x: len(x) == 12)\n",
    "rate_12= pd.DataFrame(rate_12)\n",
    "rate_12.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regroupement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_quart = rate_12.resample('Q-JAN').mean()\n",
    "#print(rate_quart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jointure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignorer les jours dans l'index\n",
    "rate_quart.index =rate_quart.index.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivotage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_table = merged.melt(id_vars='merged.index', var_name='Country', value_name='Value')\n",
    "# result_table = merged.pivot(index='gdp_no_na.index', columns='rate_quart', values='gdp_no_na')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. PIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install missingno\n",
    "import pycodestyle as pep8\n",
    "import openpyxl as xl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pycountry\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation du fichier .xlsx\n",
    "gdp=pd.read_excel(\"C:/Users/yousr/Downloads/Projet_py/GDP Deflator at Market Prices, LCU.xlsx\",  sheet_name='quarterly', index_col=0)\n",
    "gdp.head(5)\n",
    "gdp.index = pd.to_datetime(gdp.index)\n",
    "gdp.index =gdp.index.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noms des colonnes\n",
    "col_names=gdp.columns\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type de données de chaque colonne \n",
    "datas_type= gdp.dtypes\n",
    "print(datas_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = gdp[gdp.duplicated()]\n",
    "duplicates.head(5) # 0 doublons dans notre gdp_no_na"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erreurs de frappes pour la colonne index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp.index = pd.to_datetime(gdp.index, errors='coerce')\n",
    "errors = gdp[gdp.index.isnull()]\n",
    "print(errors) # Pas d'erreurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type de données de chaque colonne \n",
    "datas_type= gdp.dtypes\n",
    "print(datas_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction de la DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garder uniquement les pays dans la gdp_filter_sort : Méthode search_fuzzy de pycountry ###############################################################\n",
    "\n",
    "def detect_countries(col_names):\n",
    "    countries_detected = []\n",
    "    \n",
    "    for name in col_names:\n",
    "        try:\n",
    "            # Essayer de trouver le pays par son nom\n",
    "            pays= pycountry.countries.search_fuzzy(name)[0]\n",
    "            countries_detected.append(pays.name)\n",
    "        except LookupError:\n",
    "            # Ignorer les noms qui ne correspondent à aucun pays\n",
    "            pass\n",
    "    \n",
    "    return countries_detected\n",
    "\n",
    "# Liste des pays detectés\n",
    "\n",
    "countries_detected = detect_countries(col_names)\n",
    "print(\"Noms de pays détectés :\", countries_detected)\n",
    "\n",
    "# Longeur des listes : countries_detected et col_names\n",
    "print(len(countries_detected))\n",
    "print(len(col_names))\n",
    "\n",
    "# Différence entre les deux listes pour obtenir les noms des colonnes ignorées par la fonction detect_countries\n",
    "#L'objectif est de vérifier si des pays ont été omis par la fonction detect_countries\n",
    "\n",
    "# Pays dans col_names et pas dans countries_detected\n",
    "diff= list(set(col_names) - set(countries_detected))\n",
    "print(diff) \n",
    "\n",
    "# Pays dans countries_detected et pas dans col_names\n",
    "diff2= list(set(countries_detected)- set(col_names))\n",
    "print(diff2)\n",
    "\n",
    "countries_omitted =['Korea, Rep.', 'Czech Republic', 'Taiwan, China', 'Bolivia', 'Hong Kong SAR, China', 'Egypt, Arab Rep.'] ####################\"\"\n",
    "concat = countries_detected + countries_omitted \n",
    "\n",
    "# Enfin, la liste finale des pays à retenir dans la gdp_filter_sort\n",
    "countries_detected =list(set(concat)- set(diff2))\n",
    "print(countries_detected)\n",
    "\n",
    "# La gdp_filter_sort taux de chomage à retenir\n",
    "gdp_filter= gdp[countries_detected]\n",
    "gdp_filter.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour faciliter la lecture de la gdp_filter_sort, on remplace les noms des pays par leurs codes ISO  correspondant\n",
    "\n",
    "# Dictionnaire de correspondance entre noms complets des pays et leurs codes\n",
    "corresp = {country.name: country.alpha_3 for country in pycountry.countries}\n",
    "\n",
    "# Liste initiale des noms complets des colonnes\n",
    "country = countries_detected\n",
    "# Transformation des noms complets des colonnes en abréviations\n",
    "country_codes = [corresp.get(pays, pays) for pays in country]\n",
    "\n",
    "# Remplacement des noms des pays par leurs codes dans la gdp_filter_sort\n",
    "gdp_filter.columns=country_codes\n",
    "gdp_filter.columns\n",
    "gdp_filter.head(5)\n",
    "\n",
    "#Ordre alphabétique des colonnes \n",
    "gdp_filter_sort= gdp_filter.sort_index(axis=1)\n",
    "gdp_filter_sort.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de lignes d'une gdp_filter_sort\n",
    "count_rows= len(gdp_filter_sort)\n",
    "print(count_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagramme à barres des valeurs manquantes\n",
    "msno.bar(gdp_filter_sort)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# % des NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le taux de valeurs manquantes\n",
    "size = gdp_filter_sort.shape\n",
    "nan_values = gdp_filter_sort.isna().sum()\n",
    "nan_percent = nan_values.sort_values(ascending=True) * 100 / size[0]\n",
    "print(nan_percent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seuil des NA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les colonnes avec un pourcentage de valeurs manquantes supérieur à 40%\n",
    "cols_to_drop = nan_percent[nan_percent > 40].index\n",
    "print(cols_to_drop)\n",
    "\n",
    "# Supprimer les colonnes de la DataFrame\n",
    "gdp_filter_sort.drop(cols_to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir l'index en type date { Les données sont trimestriels}\n",
    "gdp_filter_sort.index = pd.to_datetime(gdp_filter_sort.index)\n",
    "\n",
    "# Afficher le DataFrame\n",
    "print(gdp_filter_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for col in gdp_filter_sort.columns:\n",
    "    plt.plot(gdp_filter_sort.index, gdp_filter_sort[col], label=col, alpha=0.7)\n",
    "\n",
    "# Ajouter des titres et une légende\n",
    "plt.title('Séries temporelles pour chaque colonne de la DataFrame')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Valeur')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Faire pivoter les étiquettes de l'axe des x\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation des valeurs manquantes NA par interpolation\n",
    "\n",
    "# Interpolation linéaire :\n",
    "\n",
    "# gdp_filter_sort.interpolate(method='linear', limit=None)\n",
    "\n",
    "# Interpolation polynômiale d'ordre 3 :\n",
    "\n",
    "# gdp_filter_sort.interpolate(method='polynomial', order=3, limit=None)\n",
    "              \n",
    "gdp_no_na = gdp_filter_sort.fillna(gdp_filter_sort.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valeurs abérrantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les valeurs abérrantes \n",
    "\"\"\"plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=gdp_no_na)\n",
    "plt.title('Boîtes à moustaches des séries temporelles')\n",
    "plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_no_na.index = pd.to_datetime(gdp_no_na.index, format='%Y-%m')\n",
    "\n",
    "# Grouper par année et vérifier si tous les trimestres sont présents\n",
    "gdp_no_na = gdp_no_na.groupby(gdp_no_na.index.year).filter(lambda x: len(x) == 4)\n",
    "gdp_no_na = pd.DataFrame(gdp_no_na)\n",
    "gdp_no_na.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow==2.7.0 \n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les DataFrames sur l'index en utilisant une jointure interne (how='inner')\n",
    "common_columns = rate_quart.columns.intersection(gdp_no_na.columns) # Pour garder uniquement les colonnes présentes dans les deux DF\n",
    "merged= pd.merge(rate_quart[common_columns], gdp_no_na[common_columns], left_index=True, right_index=True, how='inner' )\n",
    "merged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rate_quart.index)\n",
    "print(gdp_no_na.index)\n",
    "print(rate_quart.index.equals(gdp_no_na.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rate = pd.DataFrame(rate_quart.mean(), columns=['Taux de chomage'])\n",
    "mean_gdp = pd.DataFrame(gdp_no_na.mean(), columns=['PIB'])\n",
    "merged_mean= pd.merge(mean_rate, mean_gdp, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "educ=pd.read_excel(\"C:/Users/yousr/Downloads/Projet_py/BIg_data.xlsx\", sheet_name='HNP_StatsData', header=1, index_col=0)\n",
    "educ.head(5)\n",
    "col_names=educ.columns\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Life Expectancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masque = educ['Indicator Name'].str.contains('expectancy', case=False) & educ['Indicator Name'].str.contains('total', case=False)\n",
    "# Appliquez le masque pour obtenir un nouveau DataFrame avec les lignes filtrées\n",
    "educ_LE = educ[masque]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les colonnes qui contiennent des années ou les noms des pays\n",
    "cols_to_keep = educ_LE.columns[educ_LE.columns.str.contains(r'\\d{4}|Indicator Name')]\n",
    "\n",
    "# Créer un nouveau DataFrame avec les colonnes filtrées\n",
    "educ_LE_col = educ_LE[cols_to_keep]\n",
    "print(educ_LE_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "educ_LE_col = educ_LE_col.drop(columns=\"Indicator Name\")\n",
    "mean_LE = educ_LE_col.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_LE =mean_LE.to_frame(name='Life Expectancy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population growth rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masque1 = educ['Indicator Name'].str.contains('Population growth ', case=False)\n",
    "educ_PGR = educ[masque1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les colonnes qui contiennent des années ou les noms des pays\n",
    "cols_to_keep1 = educ_PGR.columns[educ_PGR.columns.str.contains(r'\\d{4}|Indicator Name')]\n",
    "\n",
    "# Créer un nouveau DataFrame avec les colonnes filtrées\n",
    "educ_PGR_filter1 = educ_PGR[cols_to_keep1]\n",
    "print(educ_PGR_filter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = educ_PGR_filter1['Indicator Name'].unique()\n",
    "print(unique)\n",
    "\n",
    "# On souhaite garder que le taux de croissance de la population totale\n",
    "\n",
    "# Par élimination successive\n",
    "# On garde les lignes où il y a le taux de croissance du milieu hors que urbain\n",
    "masque2 = educ_PGR_filter1['Indicator Name'].str.contains('urban', case=False)\n",
    "masque2_inverse= ~masque2 # Récupérer les lignes qui ne vérifient pas le masque\n",
    "educ_PGR_filter2 = educ_PGR_filter1[masque2_inverse]\n",
    "\n",
    "# On garde les lignes où il y a le taux de croissance du milieu hors que rural\n",
    "masque3 = educ_PGR_filter2['Indicator Name'].str.contains('rural', case=False)\n",
    "masque3_inverse = ~masque3\n",
    "educ_PGR_filter3 = educ_PGR_filter2[masque3_inverse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "educ_PGR_filter3  = educ_PGR_filter3.drop(columns=\"Indicator Name\")\n",
    "mean_PGR = educ_PGR_filter3.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_PGR=mean_PGR .to_frame(name='Life Expectancy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. GMD Inégalités"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycodestyle as pep8\n",
    "import openpyxl as xl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pycountry\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation de la BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini Mean Difference\n",
    "gmd=pd.read_excel(\"C:/Users/yousr/Downloads/Projet_py/inequality GMD World Bank.xlsx\",  sheet_name='data', index_col=0)\n",
    "gmd.head(5)\n",
    "col_names=gmd.columns\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction des colonnes nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de données de l'indice Theil\n",
    "theil = gmd.pivot(index='year', columns='countryname', values='index')\n",
    "theil.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La moyenne de l'indice de theil sur toutes les périodes\n",
    "mean_theil = theil.mean(axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de données du taux d'urbanisation\n",
    "urban = gmd.pivot(index='year', columns='countryname', values='sp_urb_totl_in_zs')\n",
    "urban.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La moyenne du taux d'urbanisation sur toutes les périodes\n",
    "mean_urban = urban.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de données du ratio de pauvreté\n",
    "poverty = gmd.pivot(index='year', columns='countryname', values='si_pov_lmic')\n",
    "poverty.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La moyenne du ratio de pauvreté sur toutes les périodes\n",
    "mean_poverty = poverty.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans pandas, une Df à une colonne correspond à une série. On donne un nom à chaque série pour une éventuelle jointure\n",
    "mean_poverty.name = 'Ratio de pauvreté'\n",
    "mean_urban.name = \"Taux urbanisation\"\n",
    "mean_theil.name = 'Theil'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jointure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jointure entre df1 et df2 sur la colonne \"countryname\"\n",
    "merged1 = pd.merge(mean_poverty, mean_urban, on='countryname', how='inner')\n",
    "# Jointure entre le résultat précédent (merged_df) et df3 sur la colonne \"countryname\"\n",
    "final_merged1 = pd.merge(merged1, mean_theil, on='countryname', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dans pandas, une Df à une colonne correspond à une série. On donne un nom à chaque série pour une éventuelle jointure\n",
    "mean_LE.name = 'Espérance de vie'\n",
    "mean_PGR.name = \"Croissance démo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged1.index.name = 'Country Name'  ####################################################################################\n",
    "mean_LE.index.name = 'Country Name'\n",
    "mean_PGR.index.name = 'Country Name'\n",
    "merged_mean.index.name = 'Country Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jointure entre df1 et df2 sur la colonne \"countryname\"\n",
    "merged2 = pd.merge(final_merged1, mean_PGR, on='Country Name', how='inner')\n",
    "# Jointure entre le résultat précédent (merged_df) et df3 sur la colonne \"countryname\"\n",
    "merged3 = pd.merge(merged2, mean_LE, on='Country Name', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transposé de merged3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged3_transpose = merged3.transpose()\n",
    "col_names = merged3_transpose.columns\n",
    "merged3_transpose.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code ISO des pays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour faciliter la lecture de la DF, on remplace les noms des pays par leurs codes ISO  correspondant\n",
    "\n",
    "# Dictionnaire de correspondance entre noms complets des pays et leurs codes\n",
    "corresp = {country.name: country.alpha_3 for country in pycountry.countries}\n",
    "\n",
    "# Liste initiale des noms complets des colonnes\n",
    "country = col_names\n",
    "# Transformation des noms complets des colonnes en abréviations\n",
    "country_codes = [corresp.get(pays, pays) for pays in country]\n",
    "\n",
    "# Remplacement des noms des pays par leurs codes dans la merged\n",
    "merged3_transpose.columns=country_codes\n",
    "merged3_transpose.columns\n",
    "merged3_transpose.head(5)\n",
    "\n",
    "#Ordre alphabétique des colonnes \n",
    "merged3_transpose_sort= merged3_transpose.sort_index(axis=1)\n",
    "merged3_transpose_sort.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged4=merged3_transpose.transpose()\n",
    "merged4.index.name= 'Country Name'\n",
    "merged4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged= pd.merge(merged4, merged_mean, on='Country Name', how='inner')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
