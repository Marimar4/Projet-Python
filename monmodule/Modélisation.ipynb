{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div style=\"text-align:center;\">\n",
    "  <span style=\"color:green; font-size:2em; font-weight:bold;\">Modélisation</span><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">Introduction</span><br><br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Références et équations de base de la relation d'Okun</span><br><br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons proposer une modélisation permettant de vérifier empiriquement la loi d'Okun, à partir des bases de données établies dans la partie \"Préparation_données.ipynb\".\n",
    "\n",
    "La loi d'Okun, indique que : \"chaque fois que le PIB chute d'un certain pourcentage, par rapport au produit potentiel, le taux de chômage augmente d'environ un point de pourcentage. Ainsi, lorsque le PIB réel diminue, le taux de chômage augmente.\" (Mankiw, 2003)\n",
    "\n",
    "Pour cette modélisation, on s'inspire des travaux suivants : \n",
    "\n",
    "- [1]. Traoré, D. L., Diakite, S., & Mariko, O. (2021). Croissance et chômage au Mali : Vérification empirique de la loi d'Okun. Revue Malienne de Science et de Technologie, Série C : Sciences Humaines et Sociales, 02(25), Page. ISSN 1987-1031. CNRST, Bamako, Mali.\n",
    "\n",
    "- [2]. Aassif, Z. L'extraction de la tendance cycle. Haut-Commissariat au Plan, Direction de la comptabilité nationale. \n",
    "\n",
    "- [3]. Belaidi, N. (2022, 28 mars). Validation croisée en Machine Learning. Consulté le  12 décembre 2023. URL : https://blent.ai/blog/a/validation-croisee-machine-learning.\n",
    "\n",
    "\n",
    "Le travail [1] nous présente deux équations de base de la relation d'Okun, la version en \"différences premières\" et la \"version gap\".\n",
    "\n",
    "- Version en \"différences premières\" : \n",
    "$$\\Delta u = C + \\beta\\Delta \\text{pib} + \\epsilon$$\n",
    "\n",
    "- \"Version gap\" : \n",
    "$$u - u^* = c + \\beta^*(\\text{pib} - \\text{pib}^*) + \\epsilon$$\n",
    "\n",
    "avec $u$ le taux de chômage, $u^*$ le taux de chômage naturel, $\\text{pib}^*$ le PIB potentiel et c, $\\beta$ et $\\epsilon$  des constantes à déterminer grâce à la modélisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Equation et outils utilisés dans notre modélisation</span><br><br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la modélisation, nous allons utiliser la version \"gap\", qui relie le taux de chômage et le PIB de la manière suivante : \n",
    "\n",
    "$$u - u^* = c + \\beta^*(\\text{pib} - \\text{pib}^*) + \\epsilon$$\n",
    "\n",
    "Pour extraire la tendance à long terme du taux de chômage et du PIB (c'est-à-dire, le taux de chômage naturel et le PIB potentiel), à partir de la base de données, nous allons utiliser le filtre de Hodrick-Prescott. Ce filtre est introduit dans [2], et permet de décomposer une série selon sa tendance à long terme et son cycle (fluctuations autour de la tendance) à plus court terme.\n",
    "\n",
    "Par ailleurs, pour prendre en compte la dynamique temporelle de nos données, nous allons utiliser le modèle ARDL (Auto Regressive Distributed Lag), introduit dans [2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Les différentes étapes de notre modélisation</span><br><br> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour effectuer notre modélisation sur les données obtenues suite au traitement, nous allons tout d'abord regrouper les pays présents selon différents critères, grâce à la technique du clustering. \n",
    "Nous sélectionnerons un pays de manière aléatoire au sein de chaque groupe afin de vérifier la loi d'Okun (ou alors nous vérifierons la loi d'Okun pour chaque groupe après agrégation).\n",
    "\n",
    "(Par ailleurs, nous allons utiliser une méthode de validation croisée afin de valider notre modèle. Nous allons tout d'abord établir les paramètres du modèle grâce au jeu d'entrainement reprenant les données de 1994 à 2016 ; puis nous vérifierons la précision du modèle grâce au jeu de test reprenant les données de 2017 à 2023.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> I- Extraction de la tendance à long terme du taux de chômage et du PIB</span><br><br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Importation des bases de données</span><br><br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des packages\n",
    "import declarations as d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de données obtenue suite au nettoyage\n",
    "data = d.pd.read_csv('bases/final_data.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Base de données pour la modélisation des séries temporelles </span><br><br> \n",
    "\n",
    "Pour la modélisation des séries temporelles modélisant la relation entre le PIB et le taux de chômage, nous avons besoin de ces variables pour chaque pays en colonnes et de la date en indice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de la fonction pivot pour remodeler le dataframe\n",
    "df_pivot = data.pivot(index=['YEAR'], columns='COUNTRY',\n",
    "                    values=['Unemployment_rate', 'GDP_rate'])\n",
    "\n",
    "# Ajuster les noms de colonnes\n",
    "df_pivot.columns = [f'{col[1]}_{col[0].lower()}' for col in df_pivot.columns]\n",
    "\n",
    "# Réinitialiser l'index pour avoir les colonnes YEAR et MONTH comme des colonnes régulières\n",
    "df_pivot.reset_index(inplace=True)\n",
    "\n",
    "# Afficher le nouveau dataframe\n",
    "df_pivot.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_pivot.rename(columns=lambda x: x.replace('_rate', ''))\n",
    "df_pivot.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Base de données pour le clustering </span><br><br> \n",
    "\n",
    "Pour le clustering, nous avons besoin d'une base de données avec en indice le nom des pays et en colonnes, les différents critères considérés, moyennés sur la période considérée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de la fonction pivot pour remodeler le dataframe\n",
    "df_cluster = data.pivot_table(index='COUNTRY', values=['Unemployment_rate', 'GDP_rate','life_expentancy',\n",
    "       'pop_growth_rate'], aggfunc='mean')\n",
    "\n",
    "df_cluster.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">Extraction de la tendance à long terme pour le taux de chômage (unemployement)</span><br><br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire toutes les colonnes avec le suffixe \"_rate\" ainsi que la colonne des dates\n",
    "columns_unemployment = ['YEAR'] + [col for col in df_pivot.columns if col.endswith('_unemployment')] \n",
    "df_unemployment = df_pivot[columns_unemployment]\n",
    "df_unemployment.set_index('YEAR', inplace = True)\n",
    "\n",
    "df_unemployment.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">Extraction de la tendance à long terme pour le PIB (gdp)</span><br><br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire toutes les colonnes avec le suffixe \"_gdp\" ainsi que la colonne des dates\n",
    "columns_gdp = ['YEAR'] + [col for col in df_pivot.columns if col.endswith('_gdp')] \n",
    "df_gdp = df_pivot[columns_gdp]\n",
    "df_gdp.set_index('YEAR', inplace = True)\n",
    "\n",
    "df_gdp.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> II- Clustering : regroupement des pays selon des critères de développement</span><br><br> \n",
    "\n",
    "Dans cette partie, on va utiliser la méthode du clustering pour regrouper les pays de la base de données selon 4 critères : \n",
    "<div style=\"margin-left: 20px;\">\n",
    "    <span style=\"font-weight:bold;\">1.</span> Le PIB,<br>\n",
    "    <span style=\"font-weight:bold;\">2.</span> Le taux de chômage,<br>\n",
    "    <span style=\"font-weight:bold;\">3.</span> L'espérance de vie,<br>\n",
    "    <span style=\"font-weight:bold;\">4.</span> et le taux de croissance démographique.\n",
    "    </div><br>\n",
    "    Chaque variable moyennée sur la période considérée. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les lignes ayant des valeurs manquantes\n",
    "df_cluster.dropna(inplace=True)\n",
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardiser les données (important pour K-means)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_cluster)\n",
    "\n",
    "# Appliquer l'algorithme K-means\n",
    "num_clusters = 4  # Choisissez le nombre de clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "df_cluster['Cluster'] = kmeans.fit_predict(df_scaled)\n",
    "\n",
    "# Visualisation en 3D (utilisant les variables GDP_rate, Life_expectance, Pop_growth_rate)\n",
    "fig = d.plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df_scaled[:, 1], df_scaled[:, 2], df_scaled[:, 3], c=df_cluster['Cluster'], cmap='viridis', s=50)\n",
    "ax.set_xlabel('GDP_rate')\n",
    "ax.set_ylabel('Life_expectancy')\n",
    "ax.set_zlabel('Pop_growth_rate')\n",
    "d.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les groupes et les pays\n",
    "for cluster_num in range(num_clusters):\n",
    "    countries_in_cluster = df_cluster[df_cluster['Cluster'] == cluster_num].index\n",
    "    print(f'Cluster {cluster_num + 1}: {list(countries_in_cluster)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> III- Vérification de la loi pour un pays tiré aléatoirement dans chaque groupe</span><br><br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation de la relation entre PIB et taux de chômage, pour un pays donné, grâce au modèle ARDL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction de la tendance à long terme du PIB et du taux de chômage d'un pays.\n",
    "\n",
    "Dans cette partie, on définit une classe qui permet de tracer la tendance à long terme et les cycles à court terme des deux variables considérées. \n",
    "\n",
    "La méthode df_gap() de cette classe permet d'obtenir une série avec les valeurs de la différence entre la valeur réelle et la tendance à long terme des deux variables considérées, pour un pays considéré. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountryData:\n",
    "    def __init__(self, country_code, unemployment_data, gdp_data):\n",
    "        \"\"\"\n",
    "        Initialize a CountryData instance.\n",
    "\n",
    "        Parameters:\n",
    "        - country_code (str): The country code.\n",
    "        - unemployment_data (pd.Series): Time series data for unemployment rate.\n",
    "        - gdp_data (pd.Series): Time series data for GDP rate.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.country_code = country_code\n",
    "        self.unemployment_rate = unemployment_data[f'{country_code}_unemployment']\n",
    "        self.gdp_rate = gdp_data[f'{country_code}_gdp']\n",
    "\n",
    "    def plot_trend_cycle(self):\n",
    "        \"\"\"\n",
    "        Plot the trend and cycle components for unemployment rate and GDP rate after applying the Hodrick-Prescott filter to the time series.\n",
    "        \"\"\"\n",
    "        # Extraction of the long-term trend of unemployment rate\n",
    "        x = self.unemployment_rate\n",
    "\n",
    "        # Applying the Hodrick-Prescott filter\n",
    "        trend_x, cycle_x = d.smf.hpfilter(x, lamb=1600)\n",
    "\n",
    "        # Plot the trend and cycle of unemployment rate\n",
    "        d.plt.plot(x, label='Original series')\n",
    "        d.plt.plot(trend_x, label='Trend')\n",
    "        d.plt.plot(cycle_x, label='Cycle')\n",
    "        d.plt.legend()\n",
    "        d.plt.show()\n",
    "\n",
    "        # Extraction of the long-term trend of GDP\n",
    "        y = self.gdp_rate\n",
    "\n",
    "        # Applying the Hodrick-Prescott filter\n",
    "        trend_y, cycle_y = d.smf.hpfilter(y, lamb=1600)\n",
    "\n",
    "        # Plot the trend and cycle of the trend\n",
    "        d.plt.plot(y, label='Originale series')\n",
    "        d.plt.plot(trend_y, label='Trend')\n",
    "        d.plt.plot(cycle_y, label='Cycle')\n",
    "        d.plt.legend()\n",
    "        d.plt.show()\n",
    "        \n",
    "    def df_gap(self):\n",
    "        \"\"\"\n",
    "        Calculate the gap series for unemployment rate and GDP rate.\n",
    "\n",
    "        Returns:\n",
    "        - df_gap (pd.DataFrame): DataFrame containing the gap values.\n",
    "        \"\"\"\n",
    "        # Extraction of the long-term trend of unemployment rate\n",
    "        x = self.unemployment_rate\n",
    "\n",
    "        # Applying the Hodrick-Prescott filter\n",
    "        trend_x, cycle_x = d.smf.hpfilter(x, lamb=1600)\n",
    "    \n",
    "        # Extraction of the long-term trend of GDP\n",
    "        y = self.gdp_rate\n",
    "\n",
    "        # Applying the Hodrick-Prescott filter\n",
    "        trend_y, cycle_y = d.smf.hpfilter(y, lamb=1600)\n",
    "    \n",
    "        # Calculate the new series by removing the trend\n",
    "        gap_unemployment = x - trend_x\n",
    "        gap_gdp = y - trend_y\n",
    "\n",
    "        # Create a DataFrame with the new series\n",
    "        df_x = d.pd.DataFrame({'YEAR': x.index, 'gap_unemployment': gap_unemployment.values})\n",
    "        df_y = d.pd.DataFrame({'YEAR': y.index, 'gap_gdp': gap_gdp.values})\n",
    "\n",
    "        # Merge the DataFrames on the 'YEAR' column\n",
    "        df_gap = d.pd.merge(df_x, df_y, on='YEAR', how='inner')\n",
    "\n",
    "        return df_gap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle ARDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium = CountryData('BEL', df_unemployment, df_gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium.df_gap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_series = belgium.df_gap()['gap_unemployment']\n",
    "gdp_series = belgium.df_gap()['gap_gdp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions tout d'abord la stationnarité de la série"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour effectuer le test ADF et imprimer les résultats\n",
    "def perform_adf_test(series, name):\n",
    "    result = adfuller(series, autolag='AIC')\n",
    "    print(f'Test ADF pour la série {name}:')\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    print(f'Nombre de lags utilisés: {result[2]}')\n",
    "    print(f'Nombre d\\'observations utilisées: {result[3]}')\n",
    "    print(f'Valeurs critiques:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'   {key}: {value}')\n",
    "\n",
    "# Appliquer le test ADF pour le taux de chômage et le PIB réel\n",
    "perform_adf_test(unemployment_series, 'Unemployment_rate')\n",
    "perform_adf_test(gdp_series, 'Real_GDP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Des p-values de 0.8840503707945941 et de 1.0 indiquent que nous ne pouvons pas rejeter l'hypothèse nulle selon laquelle les séries ne sont pas stationnaires. En d'autres termes, cela suggère que les séries ne sont pas stationnaires.\n",
    "\n",
    "Pour rendre nos séries stationnaires, nous pouvons envisager de les différencier. La différenciation consiste à soustraire chaque observation de l'observation précédente. nous pouvons utiliser la fonction diff() de pandas pour effectuer cette opération. Voici comment nous pouvons le faire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Différenciation des séries temporelles\n",
    "diff_unemployment_series = unemployment_series.diff().dropna()\n",
    "diff_gdp_series = gdp_series.diff().dropna()\n",
    "\n",
    "# Réappliquer le test ADF aux séries différenciées\n",
    "perform_adf_test(diff_unemployment_series, 'Diff_Unemployment_rate')\n",
    "perform_adf_test(diff_gdp_series, 'Diff_Real_GDP')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs des p-values sont toujours trop élevées pour les deux séries et ne permettent pas de rejeter l'hypothèse nulle. \n",
    "\n",
    "Cela suggère que même après la première différenciation, les séries nen sont pas encore stationnaire.\n",
    "Nous pouvons envisager d'effectuer une différenciation supplémentaire pour voir si cela améliore la stationnarité des séries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deuxième différenciation pour Diff_Unemployment_series\n",
    "diff2_unemployment_series = diff_unemployment_series.diff().dropna()\n",
    "\n",
    "# Deuxième différenciation pour Diff_Real_GDP\n",
    "diff2_gdp_series = diff_gdp_series.diff().dropna()\n",
    "\n",
    "# Test ADF pour la deuxième différenciation\n",
    "perform_adf_test(diff2_unemployment_series, 'Diff2_Unemployment_Series')\n",
    "# Test ADF pour la deuxième différenciation\n",
    "perform_adf_test(diff2_gdp_series, 'Diff2_Real_GDP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs des p-values pour la deuxième différenciation des deux séries sont faibles. Cela suggère que, après la deuxième différenciation, nous pouvons rejeter l'hypothèse nulle selon laquelle chaque série n'est pas stationnaire. Par conséquent, les deux sérries obtenues après deux différentiations semblent être stationnaires.\n",
    "\n",
    "Cela est une bonne nouvelle car la stationnarité est une condition importante pour l'application de modèles ARDL. À ce stade, nous pouvons utiliser les séries temporelles différenciées (2 fois) dans notre modèle ARDL pour étudier la relation entre le taux de chômage et le PIB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par ailleurs, il faut également prendre en compte le nombre approprié de retards (lags) pour chaque variable afin de spécifier correctement notre modèle.\n",
    "Pour déterminer le nombre optimal de retards (lags) dans un modèle ARDL, nous pouvons utiliser des graphiques de la fonction d'autocorrélation (ACF) et de la fonction d'autocorrélation partielle (PACF). Ces graphiques peuvent nous aider à identifier les retards significatifs qui affectent la série temporelle.\n",
    "Ces graphiques aident à visualiser les corrélations entre les observations à différents retards. Nous devons rechercher des retards significatifs où les corrélations sont en dehors de l'intervalle de confiance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Supposons que df_diff soit votre DataFrame avec les séries temporelles différenciées\n",
    "# Vous pouvez remplacer 'Diff_Unemployment_rate' et 'Diff_Real_GDP' par les noms réels de vos colonnes.\n",
    "df_diff = d.pd.DataFrame({\n",
    "    'Diff2_Unemployment_rate': diff2_unemployment_series,\n",
    "    'Diff2_Real_GDP': diff2_gdp_series\n",
    "})\n",
    "\n",
    "# Tracez les fonctions d'autocorrélation (ACF) et d'autocorrélation partielle (PACF)\n",
    "fig, ax = d.plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# ACF\n",
    "plot_acf(df_diff['Diff2_Unemployment_rate'], ax=ax, lags=40, title='ACF - Diff2_Unemployment_rate')\n",
    "d.plt.show()\n",
    "\n",
    "# PACF\n",
    "fig, ax = d.plt.subplots(figsize=(12, 6))\n",
    "plot_pacf(df_diff['Diff2_Unemployment_rate'], ax=ax, lags=40, title='PACF - Diff2_Unemployment_rate')\n",
    "d.plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le premier pic dans la fonction d'autocorrélation (ACF) est très élevé et significatif, et qu'il est en dehors de l'intervalle de confiance, cela suggère qu'un seul retard (lag = 1) pourrait être suffisant pour capturer l'autocorrélation significative dans nos données.\n",
    "\n",
    "Choisir un seul retard peut également simplifier notre modèle ARDL et le rendre plus interprétable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracez les fonctions d'autocorrélation (ACF) et d'autocorrélation partielle (PACF) pour GDP\n",
    "fig, ax = d.plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# ACF\n",
    "plot_acf(df_diff['Diff2_Real_GDP'], ax=ax, lags=40, title='ACF - Diff2_Real_GDP')\n",
    "d.plt.show()\n",
    "\n",
    "# PACF\n",
    "fig, ax = d.plt.subplots(figsize=(12, 6))\n",
    "plot_pacf(df_diff['Diff2_Real_GDP'], ax=ax, lags=40, title='PACF - Diff2_Real_GDP')\n",
    "d.plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle présenté ci-dessous est une spécification simple d'un modèle ARDL (AutoRegressive Distributed Lag). Cependant, la dynamique temporelle est partiellement prise en compte dans la mesure où le modèle inclut un lag du taux de chômage (Diff_Unemployment_rate) pour capturer l'effet retardé sur la variable dépendante (Diff2_Real_GDP).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Définir les lags appropriés\n",
    "lags_ur = 6  # Lags pour Diff2_Unemployment_rate\n",
    "lags_gdp = 8  # Lags pour Diff2_Real_GDP\n",
    "\n",
    "# Créer les matrices de variables explicatives\n",
    "x = sm.add_constant(df_diff[['Diff2_Unemployment_rate', 'Diff2_Real_GDP']])\n",
    "for lag in range(1, max(lags_ur, lags_gdp) + 1):\n",
    "    x[f'Diff2_Unemployment_rate_{lag}'] = df_diff['Diff2_Unemployment_rate'].shift(lag)\n",
    "    x[f'Diff2_Real_GDP_{lag}'] = df_diff['Diff2_Real_GDP'].shift(lag)\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes\n",
    "x = x.dropna()\n",
    "\n",
    "# Définir la variable dépendante\n",
    "y = df_diff['Diff2_Real_GDP'].shift(-1).dropna()\n",
    "\n",
    "# Vérifier que les deux dataframes ont bien les mêmes données\n",
    "Y = y[y.index.isin(x.index)]\n",
    "X = x[x.index.isin(Y.index)]\n",
    "\n",
    "# Ajuster le modèle ARDL\n",
    "model = sm.OLS(Y, X)\n",
    "results = model.fit()\n",
    "\n",
    "# Afficher les résultats\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats de la régression indiquent ce qui suit pour le modèle ARDL que nous avons ajusté :\n",
    "\n",
    "- R-squared : Le coefficient de détermination () est proche de zéro (0.000), ce qui suggère que le modèle n'explique qu'une très faible proportion de la variabilité de la variable dépendante (Diff2_Real_GDP).\n",
    "\n",
    "- Coefficients :\n",
    "    - Intercept : Le coefficient associé à l'intercept est proche de zéro (0.0001) et non significatif (p-value de 0.878).\n",
    "    - Diff_Unemployment_rate : Le coefficient associé à la variable explicative (Diff_Unemployment_rate) est également proche de zéro (-0.0006) et non significatif (p-value de 0.823).\n",
    "\n",
    "- Statistiques de test :\n",
    "    - F-statistic : La statistique F (0.05047) est très faible, indiquant une faible significativité globale du modèle.\n",
    "    - Prob (F-statistic) : La p-value associée à la statistique F est élevée (0.823), ce qui suggère que le modèle dans son ensemble n'est pas statistiquement significatif.\n",
    "\n",
    "- Autres informations :\n",
    "    - Log-Likelihood : La valeur de la log-vraisemblance (-725.1) est utilisée pour comparer différents modèles. Des valeurs plus basses sont préférées, mais cela dépend également du contexte.\n",
    "\n",
    "En conclusion, les résultats suggèrent que le modèle actuel n'est pas statistiquement significatif et n'explique qu'une très faible proportion de la variabilité de Diff2_Real_GDP. Il peut être nécessaire de reconsidérer la spécification du modèle, d'explorer d'autres variables explicatives potentielles ou de prendre en compte des lags supplémentaires. De plus, la violation de l'hypothèse de normalité des résidus peut indiquer des problèmes potentiels avec le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tirage d'un pays de manière aléatoire dans chaque cluster et application du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le pays sélectionné de manière aléatoire dans chaque cluster\n",
    "list_random_countries = []\n",
    "for cluster_num in range(num_clusters):\n",
    "    countries_in_cluster = df_cluster[df_cluster['Cluster'] == cluster_num].index\n",
    "    random_country = d.np.random.choice(countries_in_cluster)\n",
    "    list_random_countries.append(random_country)\n",
    "    print(f'Cluster {cluster_num + 1}: {random_country}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
