{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imstallation et importation des packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" %pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install openpyxl\n",
    "%pip install pycodestyle\n",
    "%pip install pycountry\n",
    "%pip install seaborn\n",
    "%pip install pickleshare\"\"\"\n",
    "import pycodestyle as pep8\n",
    "import openpyxl as xl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pycountry\n",
    "import seaborn as sns\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation de la BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate=pd.read_excel(\"C:/Users/yousr/Downloads/Projet_py/Unemployment Rate.xlsx\", sheet_name='monthly' , index_col=0 )\n",
    "rate.head(5)\n",
    "rate.index = pd.to_datetime(rate.index,format='%YM%m')\n",
    "rate.index =rate.index.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noms des colonnes\n",
    "col_names=rate.columns\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type de données de chaque colonne \n",
    "datas_type= rate.dtypes\n",
    "print(datas_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = rate[rate.duplicated()]\n",
    "duplicates.head(5) # 0 doublons dans notre DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erreurs de frappes pour la colonne index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate.index = pd.to_datetime(rate.index, errors='coerce')\n",
    "errors = rate[rate.index.isnull()]\n",
    "errors.head(10) # Pas d'erreurs #########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction de DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garder uniquement les pays dans la DF : Méthode search_fuzzy de pycountry ###############################################################\n",
    "\n",
    "def detect_countries(col_names):\n",
    "    countries_detected = []\n",
    "    \n",
    "    for name in col_names:\n",
    "        try:\n",
    "            # Essayer de trouver le pays par son nom\n",
    "            pays= pycountry.countries.search_fuzzy(name)[0]\n",
    "            countries_detected.append(pays.name)\n",
    "        except LookupError:\n",
    "            # Ignorer les noms qui ne correspondent à aucun pays\n",
    "            pass\n",
    "    \n",
    "    return countries_detected\n",
    "\n",
    "# Liste des pays detectés\n",
    "\n",
    "countries_detected = detect_countries(col_names)\n",
    "print(\"Noms de pays détectés :\", countries_detected)\n",
    "\n",
    "# Longeur des listes : countries_detected et col_names\n",
    "print(len(countries_detected))\n",
    "print(len(col_names))\n",
    "\n",
    "# Différence entre les deux listes pour obtenir les noms des colonnes ignorées par la fonction detect_countries\n",
    "#L'objectif est de vérifier si des pays ont été omis par la fonction detect_countries\n",
    "\n",
    "# Pays dans col_names et pas dans countries_detected\n",
    "diff= list(set(col_names) - set(countries_detected))\n",
    "print(diff) \n",
    "\n",
    "# Pays dans countries_detected et pas dans col_names\n",
    "diff2= list(set(countries_detected)- set(col_names))\n",
    "print(diff2)\n",
    "\n",
    "countries_omitted =['Korea, Rep.', 'Taiwan, China', 'Hong Kong SAR, China', 'Czech Republic', 'Egypt, Arab Rep.', 'Venezuela, RB'] ####################\"\"\n",
    "concat = countries_detected + countries_omitted \n",
    "\n",
    "# Enfin, la liste finale des pays à retenir dans la DF\n",
    "countries_detected =list(set(concat)- set(diff2))\n",
    "print(countries_detected)\n",
    "\n",
    "# La DF taux de chomage à retenir\n",
    "rate_filter= rate[countries_detected]\n",
    "rate_filter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour faciliter la lecture de la DF, on remplace les noms des pays par leurs codes ISO  correspondant\n",
    "\n",
    "# Dictionnaire de correspondance entre noms complets des pays et leurs codes\n",
    "corresp = {country.name: country.alpha_3 for country in pycountry.countries}\n",
    "\n",
    "# Liste initiale des noms complets des colonnes\n",
    "country = countries_detected\n",
    "# Transformation des noms complets des colonnes en abréviations\n",
    "country_codes = [corresp.get(pays, pays) for pays in country]\n",
    "\n",
    "# Remplacement des noms des pays par leurs codes dans la merged\n",
    "rate_filter.columns=country_codes\n",
    "rate_filter.columns\n",
    "rate_filter.head(5)\n",
    "\n",
    "#Ordre alphabétique des colonnes \n",
    "rate_filter_sort= rate_filter.sort_index(axis=1)\n",
    "rate_filter_sort.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des valeurs manquantes NA\n",
    "import missingno as msno\n",
    "# Diagramme à barres des valeurs manquantes\n",
    "msno.bar(rate_filter_sort)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# % des NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le taux de valeurs manquantes dans chaque colonne\n",
    "size = rate_filter_sort.shape\n",
    "nan_sum = rate_filter_sort.isna().sum() # Total du nombre de NA par colonne\n",
    "nan_percent = nan_sum.sort_values(ascending=True) * 100 / size[0]\n",
    "print(nan_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seuil des NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les colonnes avec un pourcentage de valeurs manquantes supérieur à 40%\n",
    "cols_to_drop = nan_percent[nan_percent > 40].index\n",
    "print(cols_to_drop)\n",
    "\n",
    "# Supprimer les colonnes de la DataFrame\n",
    "rate_filter_sort.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type de données de chaque colonne \n",
    "data_type = rate_filter_sort.dtypes\n",
    "print(data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation des NA\n",
    "\n",
    "#rate_filter_sort_inter=rate_filter_sort.interpolate(method='linear', axis=0, limit=None, inplace=False, limit_direction=None, limit_area=None)\n",
    "\n",
    "#rate_filter_sort.fillna(value=None, method='ffill', axis=None, inplace=False, limit=None)\n",
    "\n",
    "rate_no_na = rate_filter_sort.fillna(rate_filter_sort.mean())\n",
    "\n",
    "#rate_filter_sort_fill= rate_filter_sort.iloc[-5:].ffill()\n",
    "\n",
    "indice_premiere_na = rate_filter_sort.isna().any(axis=1).idxmax()\n",
    "print(indice_premiere_na)\n",
    "\n",
    "#numero_ligne = rate_filter_sort.index.get_loc(indice_premiere_na) + 1\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "date_today = datetime.now()\n",
    "\n",
    "# Extrait l'année de la date actuelle\n",
    "current_year = date_today.year\n",
    "str(current_year)\n",
    "rate_filter_sort.index = pd.to_datetime(rate_filter_sort.index, format='mixed')\n",
    "\n",
    "\n",
    "rate_filter_sort.index = rate_filter_sort.index.astype(str)\n",
    "rate_current_year = rate_filter_sort[rate_filter_sort.index.str.contains(current_year)]\n",
    "\n",
    "\n",
    "#rate_filter_sort.index = pd.to_datetime(rate_filter_sort.index)\n",
    "\n",
    "#year2023 =rate_filter_sort.loc[rate_filter_sort.index.year == 2023]\n",
    "\n",
    "#.fillna(rate_filter_sort.mean())\n",
    "print(rate_filter_sort.index.dtype) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valeurs abérrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les valeurs abérrantes \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=rate_no_na)\n",
    "plt.title('Boîtes à moustaches des séries temporelles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_no_na.index = pd.to_datetime(rate_no_na.index, format='%Y-%m-%d')\n",
    "\n",
    "# Grouper par année et vérifier si tous les mois sont présents\n",
    "rate_12= rate_no_na.groupby(rate_no_na.index.year).filter(lambda x: len(x) == 12)\n",
    "rate_12= pd.DataFrame(rate_12)\n",
    "rate_12.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regroupement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_quart = rate_12.resample('Q-JAN').mean()\n",
    "#print(rate_quart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jointure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignorer les jours dans l'index\n",
    "rate_quart.index =rate_quart.index.strftime('%Y-%m')\n",
    "\n",
    "# Importation de la DF gdp_no_na grace à pickleshare \n",
    "from pickleshare import PickleShareDB\n",
    "db = PickleShareDB('~/data_store')\n",
    "gdp_no_na= db['my_dataframe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les DataFrames sur l'index en utilisant une jointure interne (how='inner')\n",
    "common_columns = rate_quart.columns.intersection(gdp_no_na.columns) # Pour garder uniquement les colonnes présentes dans les deux DF\n",
    "merged= pd.merge(rate_quart[common_columns], gdp_no_na[common_columns], left_index=True, right_index=True, how='inner' )\n",
    "merged.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rate_quart.index)\n",
    "print(gdp_no_na.index)\n",
    "print(rate_quart.index.equals(gdp_no_na.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rate = pd.DataFrame(rate_quart.mean(), columns=['Mean'])\n",
    "mean_gdp = pd.DataFrame(gdp_no_na.mean(), columns=['Mean'])\n",
    "merged_mean= pd.merge(mean_rate, mean_gdp, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivotage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_table = merged.melt(id_vars='merged.index', var_name='Country', value_name='Value')\n",
    "# result_table = merged.pivot(index='gdp_no_na.index', columns='rate_quart', values='gdp_no_na')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table_result = pd.pivot_table(merged, values=['Taux de Chômage', 'PIB'], index=['Pays'], columns=['Année'], aggfunc='mean')\n",
    "\n",
    "\n",
    "\n",
    "# Utilisez la méthode melt pour fondre la DataFrame\n",
    "melted_merged = merged.reset_index().melt(id_vars=['index'], var_name='Variable', value_name='Valeur')\n",
    "\n",
    "# Renommez la colonne 'index' en 'Année'\n",
    "melted_merged = melted_merged.rename(columns={'index': 'Année'})\n",
    "\n",
    "# Séparez la colonne 'Variable' en deux colonnes 'Pays' et 'Indicateur'\n",
    "melted_merged[['Pays', 'Indicateur']] = melted_merged['Variable'].str.split('_', expand=True)\n",
    "\n",
    "# Supprimez la colonne 'Variable' maintenant inutile\n",
    "melted_merged = melted_merged.drop(columns=['Variable'])\n",
    "\n",
    "# Réglez l'index sur 'Année' si vous le souhaitez\n",
    "melted_merged = melted_merged.set_index('Année')\n",
    "\n",
    "# Affichez le résultat\n",
    "print(melted_merged)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
